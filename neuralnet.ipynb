{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOYBlY+6w51Omi9Cp5EDVWC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WillRWhite/Colab/blob/main/neuralnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X8CXUO6WeszX"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "class NetLayer:\n",
        "\n",
        "    # The \"instance_count\" class variable will be incremented in the \"__init__\" method each time the class is instasnciated\n",
        "    # Usefull for debugging. Can be removed in final release\n",
        "    instance_count = 0\n",
        "\n",
        "    def __init__(self, inputs, out_len):\n",
        "        # Increment the instance_count each time NetLayer is instanciated\n",
        "        NetLayer.instance_count += 1\n",
        "\n",
        "        self.inputs = inputs\n",
        "        input_len = np.size(inputs)\n",
        "        print(\"Input size =\", input_len)\n",
        "        self.weights = np.random.uniform(-1, 1, (input_len, out_len))\n",
        "        self.bias = np.random.uniform(-1, 1, out_len)\n",
        "        if out_len > input_len:\n",
        "            # Debug code to identify which instance\n",
        "            #print(f\"{self.__class__.__name__} has been called by instance{NetLayer.instance_count}\")\n",
        "            # For a neural net layer the outputs should normally be less than the inputs\n",
        "            print(\"NetLayer instance\",NetLayer.instance_count,\":- Warning more outputs(\" + str(out_len) + \") then inputs(\" + str(input_len) + \")\")\n",
        "        print(\"Weights =\", self.weights)\n",
        "\n",
        "    def forward(self, a=\"R\"):\n",
        "        #print(a)\n",
        "        outputs = np.matmul(self.inputs, self.weights) + self.bias\n",
        "        # Sigmoid activation\n",
        "        if a == \"S\":\n",
        "            print(\"Sigmoid Activation\")\n",
        "            pass\n",
        "        # RelU activation\n",
        "        # \"R\" or any other input\n",
        "        else:\n",
        "            print(\"RelU Activation\")\n",
        "            pass\n",
        "        return outputs\n",
        "\n",
        "# Some input samples:\n",
        "#inputs = np.array([1,2,3,4])\n",
        "#inputs = np.array([1,2,3,4,5,6,7, 8, 9])\n",
        "inputs = np.random.randint(0,255,784)\n",
        "#print(\"Inputs=\", inputs)\n",
        "\n",
        "layer1 = NetLayer(inputs, 16)\n",
        "layer1_out = layer1.forward()\n",
        "print(\"layer1 Outputs =\", layer1_out )\n",
        "\n",
        "layer2 = NetLayer(layer1_out, 10 )\n",
        "layer2_out = layer2.forward(\"S\")\n",
        "print(\"layer2 Outputs =\", layer2_out )\n",
        "\n",
        "layer3 = NetLayer(layer2_out, 2)\n",
        "layer3_out = layer3.forward(\"R\")\n",
        "print(\"layer3 Outputs =\", layer3_out )"
      ]
    }
  ]
}